{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.2.2\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import lxml\n",
    "print(lxml.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://python.langchain.com//v0.1/docs/get_started/installation/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/question_answering/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/question_answering/quickstart/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/question_answering/chat_history/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/question_answering/streaming/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/question_answering/sources/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/question_answering/citations/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/question_answering/hybrid/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/question_answering/per_user/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/question_answering/conversational_retrieval_agents/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/question_answering/local_retrieval_qa/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/extraction/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/extraction/quickstart/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/extraction/guidelines/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/extraction/how_to/examples/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/extraction/how_to/handle_long_text/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/extraction/how_to/handle_files/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/extraction/how_to/parse/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/chatbots/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/chatbots/quickstart/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/chatbots/memory_management/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/chatbots/retrieval/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/chatbots/tool_usage/\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://python.langchain.com/v0.1/docs/get_started/quickstart/\"\n",
    "r = requests.get(url)\n",
    "\n",
    "# Try to use lxml parser; if not available, silently switch to html.\n",
    "soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "counter_1 = 0 \n",
    "url_list_1 = []\n",
    "\n",
    "while counter_1 < 24:\n",
    "    np = soup.find(\"a\", class_=\"pagination-nav__link pagination-nav__link--next\").get(\"href\")\n",
    "    cnp = \"https://python.langchain.com/\" + np\n",
    "    print(cnp)\n",
    "    url_list_1.append(cnp)  # Append the URL to the list\n",
    "    \n",
    "    url = cnp\n",
    "    r = requests.get(url)\n",
    "    \n",
    "    # Try to use lxml parser; if not available, silently switch to html.parser\n",
    "\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    \n",
    "    counter_1 += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://python.langchain.com//v0.1/docs/use_cases/tool_use/quickstart/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/tool_use/agents/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/tool_use/multiple_tools/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/tool_use/prompting/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/tool_use/human_in_the_loop/\n"
     ]
    }
   ],
   "source": [
    "url = \"https://python.langchain.com/v0.1/docs/use_cases/tool_use/\"\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "counter_2 = 0  # Initialize counter\n",
    "\n",
    "while counter_2 < 5:  # Continue loop until counter reaches 7\n",
    "    np = soup.find(\"a\", class_=\"pagination-nav__link pagination-nav__link--next\").get(\"href\")\n",
    "    cnp = \"https://python.langchain.com/\" + np\n",
    "    print(cnp)\n",
    "    url_list_1.append(cnp)\n",
    "\n",
    "    url = cnp\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    \n",
    "    counter_2 += 1  # Increment counter after each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://python.langchain.com//v0.1/docs/use_cases/tool_use/tool_error_handling/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/query_analysis/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/query_analysis/quickstart/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/query_analysis/how_to/few_shot/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/query_analysis/how_to/no_queries/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/query_analysis/how_to/multiple_queries/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/query_analysis/how_to/multiple_retrievers/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/query_analysis/how_to/constructing-filters/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/query_analysis/how_to/high_cardinality/\n"
     ]
    }
   ],
   "source": [
    "url = \"https://python.langchain.com/v0.1/docs/use_cases/tool_use/parallel/\"\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "counter_3 = 0  # Initialize counter\n",
    "\n",
    "while counter_3 < 9:  # Continue loop until counter reaches 7\n",
    "    np = soup.find(\"a\", class_=\"pagination-nav__link pagination-nav__link--next\").get(\"href\")\n",
    "    cnp = \"https://python.langchain.com/\" + np\n",
    "    print(cnp)\n",
    "    url_list_1.append(cnp)\n",
    "    \n",
    "\n",
    "    url = cnp\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    \n",
    "    counter_3 += 1  # Increment counter after each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://python.langchain.com//v0.1/docs/use_cases/query_analysis/techniques/expansion/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/query_analysis/techniques/hyde/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/query_analysis/techniques/routing/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/query_analysis/techniques/step_back/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/query_analysis/techniques/structuring/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/sql/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/sql/quickstart/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/sql/agents/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/sql/prompting/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/sql/query_checking/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/sql/large_db/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/sql/csv/\n"
     ]
    }
   ],
   "source": [
    "url = \"https://python.langchain.com/v0.1/docs/use_cases/query_analysis/techniques/decomposition/\"\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "counter_4 = 0  # Initialize counter\n",
    "\n",
    "while counter_4 < 12:  # Continue loop until counter reaches 7\n",
    "    np = soup.find(\"a\", class_=\"pagination-nav__link pagination-nav__link--next\").get(\"href\")\n",
    "    cnp = \"https://python.langchain.com/\" + np\n",
    "    print(cnp)\n",
    "    url_list_1.append(cnp)\n",
    "\n",
    "    \n",
    "\n",
    "    url = cnp\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    \n",
    "    counter_4 += 1  # Increment counter after each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://python.langchain.com//v0.1/docs/use_cases/graph/quickstart/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/graph/mapping/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/graph/semantic/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/graph/prompting/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/graph/constructing/\n"
     ]
    }
   ],
   "source": [
    "url = \"https://python.langchain.com/v0.1/docs/use_cases/graph/\"\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "counter_5 = 0  # Initialize counter\n",
    "\n",
    "while counter_5 < 5:  # Continue loop until counter reaches 7\n",
    "    np = soup.find(\"a\", class_=\"pagination-nav__link pagination-nav__link--next\").get(\"href\")\n",
    "    cnp = \"https://python.langchain.com/\" + np\n",
    "    print(cnp)\n",
    "    url_list_1.append(cnp)\n",
    "    url = cnp\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    \n",
    "    counter_5 += 1  # Increment counter after each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://python.langchain.com//v0.1/docs/use_cases/data_generation/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/tagging/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/summarization/\n",
      "https://python.langchain.com//v0.1/docs/use_cases/web_scraping/\n"
     ]
    }
   ],
   "source": [
    "url = \"https://python.langchain.com/v0.1/docs/use_cases/code_understanding/\"\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "counter_6 = 0  # Initialize counter\n",
    "\n",
    "while counter_6 < 4:  # Continue loop until counter reaches 7\n",
    "    np = soup.find(\"a\", class_=\"pagination-nav__link pagination-nav__link--next\").get(\"href\")\n",
    "    cnp = \"https://python.langchain.com/\" + np\n",
    "    print(cnp)\n",
    "    url_list_1.append(cnp)\n",
    "    url = cnp\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    \n",
    "    counter_6 += 1  # Increment counter after each iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXPRESSION LANGUAGE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://python.langchain.com//v0.1/docs/expression_language/get_started/\n",
      "https://python.langchain.com//v0.1/docs/expression_language/interface/\n",
      "https://python.langchain.com//v0.1/docs/expression_language/primitives/\n",
      "https://python.langchain.com//v0.1/docs/expression_language/primitives/sequence/\n",
      "https://python.langchain.com//v0.1/docs/expression_language/primitives/parallel/\n",
      "https://python.langchain.com//v0.1/docs/expression_language/primitives/binding/\n",
      "https://python.langchain.com//v0.1/docs/expression_language/primitives/functions/\n",
      "https://python.langchain.com//v0.1/docs/expression_language/primitives/passthrough/\n",
      "https://python.langchain.com//v0.1/docs/expression_language/primitives/assign/\n",
      "https://python.langchain.com//v0.1/docs/expression_language/primitives/configure/\n"
     ]
    }
   ],
   "source": [
    "url_list_2=[]\n",
    "\n",
    "url = \"https://python.langchain.com/v0.1/docs/expression_language/\"\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "counter_7 = 0  # Initialize counter\n",
    "\n",
    "while counter_7 < 10:  # Continue loop until counter reaches 7\n",
    "    np = soup.find(\"a\", class_=\"pagination-nav__link pagination-nav__link--next\").get(\"href\")\n",
    "    cnp = \"https://python.langchain.com/\" + np\n",
    "    print(cnp)\n",
    "    url_list_2.append(cnp)\n",
    "    url = cnp\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    \n",
    "    counter_7 += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://python.langchain.com//v0.1/docs/expression_language/streaming/\n",
      "https://python.langchain.com//v0.1/docs/expression_language/how_to/message_history/\n",
      "https://python.langchain.com//v0.1/docs/expression_language/how_to/routing/\n",
      "https://python.langchain.com//v0.1/docs/expression_language/how_to/inspect/\n",
      "https://python.langchain.com//v0.1/docs/expression_language/how_to/decorator/\n",
      "https://python.langchain.com//v0.1/docs/expression_language/cookbook/prompt_size/\n",
      "https://python.langchain.com//v0.1/docs/expression_language/cookbook/multiple_chains/\n"
     ]
    }
   ],
   "source": [
    "url = \"https://python.langchain.com/v0.1/docs/expression_language/why/\"\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "counter_8 = 0  # Initialize counter\n",
    "\n",
    "while counter_8 < 7:  # Continue loop until counter reaches 7\n",
    "    np = soup.find(\"a\", class_=\"pagination-nav__link pagination-nav__link--next\").get(\"href\")\n",
    "    cnp = \"https://python.langchain.com/\" + np\n",
    "    print(cnp)\n",
    "    url_list_2.append(cnp)\n",
    "    url = cnp\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    \n",
    "    counter_8 += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_save_to_file(url_list, path):\n",
    "    for i, url in enumerate(url_list, 1):\n",
    "        r = requests.get(url)\n",
    "        soup = BeautifulSoup(r.content, 'html.parser')\n",
    "        text = soup.get_text()\n",
    "        filename = f\"{i}.txt\"  # File name in ascending order\n",
    "        with open(f\"{path}/{filename}\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(text)\n",
    "\n",
    "\n",
    "\n",
    "fetch_and_save_to_file(url_list_1, \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_save_to_file(url_list, path):\n",
    "    for i, url in enumerate(url_list, 1):\n",
    "        r = requests.get(url)\n",
    "        soup = BeautifulSoup(r.content, 'html.parser')\n",
    "        text = soup.get_text()\n",
    "        filename = f\"{i}.txt\"  # File name in ascending order\n",
    "        with open(f\"{path}/{filename}\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(text)\n",
    "\n",
    "\n",
    "\n",
    "fetch_and_save_to_file(url_list_2, \"C:/Users/samar/Desktop/scrapping/data/LangChain Expression Language\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fpdf import FPDF\n",
    "import os\n",
    "\n",
    "def convert_txt_to_pdf(txt_folder, pdf_folder):\n",
    "    # Ensure the output PDF folder exists\n",
    "    os.makedirs(pdf_folder, exist_ok=True)\n",
    "\n",
    "    # Get a list of all text files in the txt_folder\n",
    "    txt_files = [f for f in os.listdir(txt_folder) if f.endswith('.txt')]\n",
    "\n",
    "    # Convert each text file to PDF\n",
    "    for txt_file in txt_files:\n",
    "        # Open the text file and read its content\n",
    "        with open(os.path.join(txt_folder, txt_file), 'r', encoding='utf-8') as file:\n",
    "            text_content = file.read()\n",
    "\n",
    "        # Create a PDF object\n",
    "        pdf = FPDF()\n",
    "        pdf.add_page()\n",
    "\n",
    "        # Add a font\n",
    "        pdf.set_font(\"Arial\", size=12)\n",
    "\n",
    "        # Add the text content to the PDF\n",
    "        pdf.multi_cell(0, 10, text_content.encode('latin-1', 'replace').decode('latin-1'))\n",
    "\n",
    "        # Save the PDF to the pdf_folder\n",
    "        pdf_output_path = os.path.join(pdf_folder, os.path.splitext(txt_file)[0] + '.pdf')\n",
    "        pdf.output(pdf_output_path)\n",
    "\n",
    "# Define the paths to the folders\n",
    "txt_folder_path = \"C:/Users/samar/Desktop/scrapping/data/Use cases/IPYNB_TEXT_usecases\"\n",
    "pdf_folder_path = \"C:/Users/samar/Desktop/scrapping/data/Use cases/IPYNB_Pdf_usecases\"\n",
    "\n",
    "# Convert text files to PDFs\n",
    "convert_txt_to_pdf(txt_folder_path, pdf_folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fpdf import FPDF\n",
    "import os\n",
    "\n",
    "def convert_txt_to_pdf(txt_folder, pdf_folder):\n",
    "    # Ensure the output PDF folder exists\n",
    "    os.makedirs(pdf_folder, exist_ok=True)\n",
    "\n",
    "    # Get a list of all text files in the txt_folder\n",
    "    txt_files = [f for f in os.listdir(txt_folder) if f.endswith('.txt')]\n",
    "\n",
    "    # Convert each text file to PDF\n",
    "    for txt_file in txt_files:\n",
    "        # Open the text file and read its content\n",
    "        with open(os.path.join(txt_folder, txt_file), 'r', encoding='utf-8') as file:\n",
    "            text_content = file.read()\n",
    "\n",
    "        # Create a PDF object\n",
    "        pdf = FPDF()\n",
    "        pdf.add_page()\n",
    "\n",
    "        # Add a font\n",
    "        pdf.set_font(\"Arial\", size=12)\n",
    "\n",
    "        # Add the text content to the PDF\n",
    "        pdf.multi_cell(0, 10, text_content.encode('latin-1', 'replace').decode('latin-1'))\n",
    "\n",
    "        # Save the PDF to the pdf_folder\n",
    "        pdf_output_path = os.path.join(pdf_folder, os.path.splitext(txt_file)[0] + '.pdf')\n",
    "        pdf.output(pdf_output_path)\n",
    "\n",
    "# Define the paths to the folders\n",
    "txt_folder_path = \"C:/Users/samar/Desktop/scrapping/data/LangChain Expression Language/Ipynb_text_files\"\n",
    "pdf_folder_path = \"C:/Users/samar/Desktop/scrapping/data/LangChain Expression Language/IPYNB_PDF_FILES\"\n",
    "\n",
    "# Convert text files to PDFs\n",
    "convert_txt_to_pdf(txt_folder_path, pdf_folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://docs.smith.langchain.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://docs.smith.langchain.com/\"\n",
    "r = requests.get(url)\n",
    "\n",
    "# Try to use lxml parser; if not available, silently switch to html.\n",
    "soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "counter_1 = 0 \n",
    "url_list_1 = []\n",
    "\n",
    "while True:\n",
    "    np = soup.find(\"a\", class_=\"pagination-nav__link pagination-nav__link--next\").get(\"href\")\n",
    "    cnp = \"https://docs.smith.langchain.com/\" + np\n",
    "    print(cnp)\n",
    "    url_list_1.append(cnp)  # Append the URL to the list\n",
    "    \n",
    "    url = cnp\n",
    "    r = requests.get(url)\n",
    "    \n",
    "    # Try to use lxml parser; if not available, silently switch to html.parser\n",
    "\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LANGSMITH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://docs.smith.langchain.com//tutorials\n",
      "https://docs.smith.langchain.com//tutorials/observability\n",
      "https://docs.smith.langchain.com//tutorials/evaluation\n",
      "https://docs.smith.langchain.com//tutorials/optimize_classifier\n",
      "https://docs.smith.langchain.com//how_to_guides\n",
      "https://docs.smith.langchain.com//how_to_guides/setup/create_account_api_key\n",
      "https://docs.smith.langchain.com//how_to_guides/setup/create_organization\n",
      "https://docs.smith.langchain.com//how_to_guides/setup/set_up_access_control\n",
      "https://docs.smith.langchain.com//how_to_guides/setup/set_up_billing\n",
      "https://docs.smith.langchain.com//how_to_guides/setup/set_up_workspace\n",
      "https://docs.smith.langchain.com//how_to_guides/tracing/annotate_code\n",
      "https://docs.smith.langchain.com//how_to_guides/tracing/toggle_tracing\n",
      "https://docs.smith.langchain.com//how_to_guides/tracing/log_traces_to_project\n",
      "https://docs.smith.langchain.com//how_to_guides/tracing/sample_traces\n",
      "https://docs.smith.langchain.com//how_to_guides/tracing/add_metadata_tags\n",
      "https://docs.smith.langchain.com//how_to_guides/tracing/distributed_tracing\n",
      "https://docs.smith.langchain.com//how_to_guides/tracing/access_current_span\n",
      "https://docs.smith.langchain.com//how_to_guides/tracing/log_multimodal_traces\n",
      "https://docs.smith.langchain.com//how_to_guides/tracing/log_retriever_trace\n",
      "https://docs.smith.langchain.com//how_to_guides/tracing/log_llm_trace\n",
      "https://docs.smith.langchain.com//how_to_guides/tracing/mask_inputs_outputs\n",
      "https://docs.smith.langchain.com//how_to_guides/tracing/export_traces\n",
      "https://docs.smith.langchain.com//how_to_guides/tracing/share_trace\n",
      "https://docs.smith.langchain.com//how_to_guides/tracing/trace_generator_functions\n",
      "https://docs.smith.langchain.com//how_to_guides/tracing/trace_with_langchain\n",
      "https://docs.smith.langchain.com//how_to_guides/tracing/trace_with_instructor\n",
      "https://docs.smith.langchain.com//how_to_guides/datasets/manage_datasets_in_application\n",
      "https://docs.smith.langchain.com//how_to_guides/datasets/manage_datasets_programmatically\n",
      "https://docs.smith.langchain.com//how_to_guides/datasets/version_datasets\n",
      "https://docs.smith.langchain.com//how_to_guides/datasets/share_dataset\n",
      "https://docs.smith.langchain.com//how_to_guides/evaluation/evaluate_llm_application\n",
      "https://docs.smith.langchain.com//how_to_guides/evaluation/bind_evaluator_to_dataset\n",
      "https://docs.smith.langchain.com//how_to_guides/evaluation/run_evaluation_from_prompt_playground\n",
      "https://docs.smith.langchain.com//how_to_guides/evaluation/evaluate_on_intermediate_steps\n",
      "https://docs.smith.langchain.com//how_to_guides/evaluation/use_langchain_off_the_shelf_evaluators\n",
      "https://docs.smith.langchain.com//how_to_guides/evaluation/compare_experiment_results\n",
      "https://docs.smith.langchain.com//how_to_guides/evaluation/evaluate_existing_experiment\n",
      "https://docs.smith.langchain.com//how_to_guides/evaluation/unit_testing\n",
      "https://docs.smith.langchain.com//how_to_guides/evaluation/evaluate_pairwise\n",
      "https://docs.smith.langchain.com//how_to_guides/human_feedback/attach_user_feedback\n",
      "https://docs.smith.langchain.com//how_to_guides/human_feedback/set_up_feedback_criteria\n",
      "https://docs.smith.langchain.com//how_to_guides/human_feedback/annotate_traces_inline\n",
      "https://docs.smith.langchain.com//how_to_guides/human_feedback/annotation_queues\n",
      "https://docs.smith.langchain.com//how_to_guides/monitoring/filter_traces_in_application\n",
      "https://docs.smith.langchain.com//how_to_guides/monitoring/use_monitoring_charts\n",
      "https://docs.smith.langchain.com//how_to_guides/monitoring/rules\n",
      "https://docs.smith.langchain.com//how_to_guides/monitoring/online_evaluations\n",
      "https://docs.smith.langchain.com//how_to_guides/monitoring/threads\n",
      "https://docs.smith.langchain.com//how_to_guides/monitoring/webhooks\n",
      "https://docs.smith.langchain.com//how_to_guides/prompts/create_a_prompt\n",
      "https://docs.smith.langchain.com//how_to_guides/prompts/update_a_prompt\n",
      "https://docs.smith.langchain.com//how_to_guides/prompts/pull_push_a_prompt\n",
      "https://docs.smith.langchain.com//how_to_guides/prompts/open_a_prompt_from_a_trace\n",
      "https://docs.smith.langchain.com//how_to_guides/prompts/langchain_hub\n",
      "https://docs.smith.langchain.com//concepts\n",
      "https://docs.smith.langchain.com//concepts/admin\n",
      "https://docs.smith.langchain.com//concepts/evaluation\n",
      "https://docs.smith.langchain.com//concepts/tracing\n",
      "https://docs.smith.langchain.com//reference\n",
      "https://docs.smith.langchain.com//reference/authentication_authorization/authentication_methods\n",
      "https://docs.smith.langchain.com//reference/data_formats/run_data_format\n",
      "https://docs.smith.langchain.com//reference/data_formats/feedback_data_format\n",
      "https://docs.smith.langchain.com//reference/data_formats/trace_query_syntax\n",
      "https://docs.smith.langchain.com//reference/sdk_reference/langchain_evaluators\n",
      "https://docs.smith.langchain.com//pricing\n",
      "https://docs.smith.langchain.com//category/self-hosting\n",
      "https://docs.smith.langchain.com//self_hosting/kubernetes\n",
      "https://docs.smith.langchain.com//self_hosting/docker\n",
      "https://docs.smith.langchain.com//self_hosting/usage\n",
      "https://docs.smith.langchain.com//self_hosting/release_notes\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://docs.smith.langchain.com/\"\n",
    "r = requests.get(url)\n",
    "\n",
    "# Use html.parser since it is already handling the parsing\n",
    "soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "\n",
    "url_list_ls_1 = []\n",
    "\n",
    "while True:\n",
    "    next_link = soup.find(\"a\", class_=\"pagination-nav__link pagination-nav__link--next\")\n",
    "    \n",
    "    # Check if the next page link is available\n",
    "    if next_link is None:\n",
    "        break  # Exit the loop if there is no next page link\n",
    "    \n",
    "    np = next_link.get(\"href\")\n",
    "    cnp = \"https://docs.smith.langchain.com/\" + np\n",
    "    print(cnp)\n",
    "    url_list_ls_1.append(cnp)  # Append the URL to the list\n",
    "    \n",
    "    url = cnp\n",
    "    r = requests.get(url)\n",
    "    \n",
    "    # Use html.parser for consistency\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_save_to_file(url_list_ls_1, path):\n",
    "    for i, url in enumerate(url_list_ls_1, 1):\n",
    "        r = requests.get(url)\n",
    "        soup = BeautifulSoup(r.content, 'html.parser')\n",
    "        text = soup.get_text()\n",
    "        filename = f\"{i}.txt\"  # File name in ascending order\n",
    "        with open(f\"{path}/{filename}\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(text)\n",
    "\n",
    "\n",
    "\n",
    "fetch_and_save_to_file(url_list_ls_1, \"C:/Users/samar/Desktop/scrapping/data/Langsmith/text_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fpdf import FPDF\n",
    "import os\n",
    "\n",
    "def convert_txt_to_pdf(txt_folder, pdf_folder):\n",
    "    # Ensure the output PDF folder exists\n",
    "    os.makedirs(pdf_folder, exist_ok=True)\n",
    "\n",
    "    # Get a list of all text files in the txt_folder\n",
    "    txt_files = [f for f in os.listdir(txt_folder) if f.endswith('.txt')]\n",
    "\n",
    "    # Convert each text file to PDF\n",
    "    for txt_file in txt_files:\n",
    "        # Open the text file and read its content\n",
    "        with open(os.path.join(txt_folder, txt_file), 'r', encoding='utf-8') as file:\n",
    "            text_content = file.read()\n",
    "\n",
    "        # Create a PDF object\n",
    "        pdf = FPDF()\n",
    "        pdf.add_page()\n",
    "\n",
    "        # Add a font\n",
    "        pdf.set_font(\"Arial\", size=12)\n",
    "\n",
    "        # Add the text content to the PDF\n",
    "        pdf.multi_cell(0, 10, text_content.encode('latin-1', 'replace').decode('latin-1'))\n",
    "\n",
    "        # Save the PDF to the pdf_folder\n",
    "        pdf_output_path = os.path.join(pdf_folder, os.path.splitext(txt_file)[0] + '.pdf')\n",
    "        pdf.output(pdf_output_path)\n",
    "\n",
    "# Define the paths to the folders\n",
    "txt_folder_path = \"C:/Users/samar/Desktop/scrapping/data/Langsmith/text_files\"\n",
    "pdf_folder_path = \"C:/Users/samar/Desktop/scrapping/data/Langsmith/Pdf_files\"\n",
    "\n",
    "# Convert text files to PDFs\n",
    "convert_txt_to_pdf(txt_folder_path, pdf_folder_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LANGSERVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://python.langchain.com/v0.1/docs/langserve/\"\n",
    "r = requests.get(url)\n",
    "\n",
    "# Use html.parser since it is already handling the parsing\n",
    "soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "def fetch_and_save_to_file(url, path):\n",
    "    for i, url in enumerate(url, 1):\n",
    "        r = requests.get(url)\n",
    "        soup = BeautifulSoup(r.content, 'html.parser')\n",
    "        text = soup.get_text()\n",
    "        filename = f\"{i}.txt\"  # File name in ascending order\n",
    "        with open(f\"{path}/{filename}\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(text)\n",
    "\n",
    "\n",
    "url_1= [url]\n",
    "fetch_and_save_to_file(url_1, \"C:/Users/samar/Desktop/scrapping/data/Langserve/text_files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LANGCHAIN INTEGRATIONS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://python.langchain.com/v0.1/docs/integrations/platforms/anthropic/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://docs.smith.langchain.com//v0.1/docs/integrations/platforms/aws/\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m count\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m25\u001b[39m:\n\u001b[0;32m     14\u001b[0m     next_link \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpagination-nav__link pagination-nav__link--next\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m     np \u001b[38;5;241m=\u001b[39m \u001b[43mnext_link\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m     cnp \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://docs.smith.langchain.com/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m np\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(cnp)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://python.langchain.com/v0.1/docs/integrations/platforms/anthropic/\"\n",
    "r = requests.get(url)\n",
    "\n",
    "# Use html.parser since it is already handling the parsing\n",
    "soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "url_list_integration_1 = []\n",
    "count=0\n",
    "\n",
    "while count<25:\n",
    "    next_link = soup.find(\"a\", class_=\"pagination-nav__link pagination-nav__link--next\").get(\"href\")\n",
    "    \n",
    "    np = next_link.get(\"href\")\n",
    "    cnp = \"https://docs.smith.langchain.com/\" + np\n",
    "    print(cnp)\n",
    "    url_list_integration_1.append(cnp)  # Append the URL to the list\n",
    "    \n",
    "    url = cnp\n",
    "    r = requests.get(url)\n",
    "    \n",
    "    # Use html.parser for consistency\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    count +=1 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://python.langchain.com//v0.1/docs/integrations/platforms/aws/\n",
      "https://python.langchain.com//v0.1/docs/integrations/platforms/google/\n",
      "https://python.langchain.com//v0.1/docs/integrations/platforms/huggingface/\n",
      "https://python.langchain.com//v0.1/docs/integrations/platforms/microsoft/\n",
      "https://python.langchain.com//v0.1/docs/integrations/platforms/openai/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/acreom/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/activeloop_deeplake/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/ai21/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/aim_tracking/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/ainetwork/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/airbyte/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/airtable/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/alchemy/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/aleph_alpha/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/alibaba_cloud/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/analyticdb/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/annoy/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/anyscale/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/apache_doris/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/apify/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/arangodb/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/arcee/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/arcgis/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/argilla/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/arthur_tracking/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/arxiv/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/assemblyai/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/astradb/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/atlas/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/awadb/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/azlyrics/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/bagel/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/baichuan/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/baidu/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/bananadev/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/baseten/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/beam/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/beautiful_soup/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/bibtex/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/bilibili/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/bittensor/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/blackboard/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/brave_search/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/breebs/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/browserbase/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/browserless/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/byte_dance/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/cassandra/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/cerebriumai/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/chaindesk/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/chroma/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/clarifai/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/clearml_tracking/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/clickhouse/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/cloudflare/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/cnosdb/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/cohere/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/college_confidential/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/comet_tracking/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/confident/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/confluence/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/context/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/couchbase/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/ctransformers/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/ctranslate2/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/cube/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/dashvector/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/databricks/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/datadog/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/datadog_logs/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/dataforseo/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/dataherald/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/deepinfra/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/deepsparse/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/diffbot/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/dingo/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/discord/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/docarray/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/doctran/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/docugami/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/docusaurus/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/dropbox/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/dspy/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/duckdb/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/edenai/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/elasticsearch/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/elevenlabs/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/epsilla/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/etherscan/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/evernote/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/exa_search/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/facebook/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/fauna/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/fiddler/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/figma/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/fireworks/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/flyte/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/forefrontai/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/geopandas/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/git/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/gitbook/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/github/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/golden/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/google_serper/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/gooseai/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/gpt4all/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/gradient/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/graphsignal/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/grobid/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/groq/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/gutenberg/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/hacker_news/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/hazy_research/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/helicone/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/hologres/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/html2text/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/huawei/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/ibm/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/ifixit/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/imsdb/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/infinispanvs/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/infinity/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/infino/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/intel/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/iugu/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/jaguar/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/javelin_ai_gateway/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/jina/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/johnsnowlabs/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/joplin/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/kdbai/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/kinetica/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/konko/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/labelstudio/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/lakefs/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/lancedb/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/langchain_decorators/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/lantern/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/llamacpp/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/llmonitor/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/log10/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/marqo/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/mediawikidump/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/meilisearch/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/metal/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/milvus/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/mindsdb/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/minimax/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/mistralai/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/mlflow/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/mlflow_ai_gateway/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/mlflow_tracking/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/modal/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/modelscope/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/modern_treasury/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/momento/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/mongodb_atlas/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/motherduck/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/motorhead/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/myscale/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/neo4j/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/nlpcloud/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/nomic/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/notion/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/nuclia/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/nvidia/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/obsidian/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/oci/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/ollama/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/ontotext_graphdb/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/openllm/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/opensearch/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/openweathermap/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/oracleai/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/outline/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/petals/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/pg_embedding/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/pgvector/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/pinecone/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/pipelineai/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/portkey/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/portkey/logging_tracing_portkey/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/predibase/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/predictionguard/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/premai/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/promptlayer/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/psychic/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/pubmed/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/pygmalionai/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/qdrant/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/ragatouille/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/ray_serve/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/rebuff/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/reddit/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/redis/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/remembrall/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/replicate/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/roam/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/robocorp/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/rockset/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/runhouse/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/rwkv/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/salute_devices/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/searchapi/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/searx/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/semadb/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/serpapi/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/shaleprotocol/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/singlestoredb/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/sklearn/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/slack/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/snowflake/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/spacy/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/sparkllm/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/spreedly/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/sqlite/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/stackexchange/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/starrocks/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/stochasticai/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/streamlit/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/stripe/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/supabase/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/symblai_nebula/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/tair/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/telegram/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/tencent/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/tensorflow_datasets/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/tidb/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/tigergraph/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/tigris/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/together/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/tomarkdown/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/trello/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/trubrics/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/trulens/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/twitter/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/typesense/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/unstructured/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/upstage/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/upstash/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/uptrain/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/usearch/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/vdms/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/vearch/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/vectara/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/vectara/vectara_chat/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/vectara/vectara_summary/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/vespa/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/vlite/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/voyageai/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/wandb_tracing/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/wandb_tracking/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/weather/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/weaviate/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/whatsapp/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/whylabs_profiling/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/wikipedia/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/wolfram_alpha/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/writer/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/xata/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/xinference/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/yandex/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/yeagerai/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/youtube/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/zep/\n",
      "https://python.langchain.com//v0.1/docs/integrations/providers/zilliz/\n",
      "https://python.langchain.com//v0.1/docs/integrations/components/\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://python.langchain.com/v0.1/docs/integrations/platforms/anthropic/\"\n",
    "r = requests.get(url)\n",
    "\n",
    "# Try to use lxml parser; if not available, silently switch to html.\n",
    "soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "url_list_integration_1 = []\n",
    "count=0\n",
    "\n",
    "while count < 268:\n",
    "    np = soup.find(\"a\", class_=\"pagination-nav__link pagination-nav__link--next\").get(\"href\")\n",
    "    cnp = \"https://python.langchain.com/\" + np\n",
    "    print(cnp)\n",
    "    url_list_integration_1.append(cnp) # Append the URL to the list\n",
    "    \n",
    "    url = cnp\n",
    "    r = requests.get(url)\n",
    "    \n",
    "    # Try to use lxml parser; if not available, silently switch to html.parser\n",
    "\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    \n",
    "    count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fpdf import FPDF\n",
    "import os\n",
    "\n",
    "def convert_txt_to_pdf(txt_folder, pdf_folder):\n",
    "    # Ensure the output PDF folder exists\n",
    "    os.makedirs(pdf_folder, exist_ok=True)\n",
    "\n",
    "    # Get a list of all text files in the txt_folder\n",
    "    txt_files = [f for f in os.listdir(txt_folder) if f.endswith('.txt')]\n",
    "\n",
    "    # Convert each text file to PDF\n",
    "    for txt_file in txt_files:\n",
    "        # Open the text file and read its content\n",
    "        with open(os.path.join(txt_folder, txt_file), 'r', encoding='utf-8') as file:\n",
    "            text_content = file.read()\n",
    "\n",
    "        # Create a PDF object\n",
    "        pdf = FPDF()\n",
    "        pdf.add_page()\n",
    "\n",
    "        # Add a font\n",
    "        pdf.set_font(\"Arial\", size=12)\n",
    "\n",
    "        # Add the text content to the PDF\n",
    "        pdf.multi_cell(0, 10, text_content.encode('latin-1', 'replace').decode('latin-1'))\n",
    "\n",
    "        # Save the PDF to the pdf_folder\n",
    "        pdf_output_path = os.path.join(pdf_folder, os.path.splitext(txt_file)[0] + '.pdf')\n",
    "        pdf.output(pdf_output_path)\n",
    "\n",
    "# Define the paths to the folders\n",
    "txt_folder_path = \"C:/Users/samar/Desktop/scrapping/data/Langserve/text_files\"\n",
    "pdf_folder_path = \"C:/Users/samar/Desktop/scrapping/data/Langserve/Pdf_files\"\n",
    "\n",
    "# Convert text files to PDFs\n",
    "convert_txt_to_pdf(txt_folder_path, pdf_folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
